<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pymasq.optimizations package &mdash; pymasq 1.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> pymasq
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="readme.html">README</a></li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">pymasq</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">pymasq</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>pymasq.optimizations package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/pymasq.optimizations.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="pymasq-optimizations-package">
<h1>pymasq.optimizations package<a class="headerlink" href="#pymasq-optimizations-package" title="Permalink to this headline"></a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline"></a></h2>
</section>
<section id="module-pymasq.optimizations.optimizations">
<span id="pymasq-optimizations-optimizations-module"></span><h2>pymasq.optimizations.optimizations module<a class="headerlink" href="#module-pymasq.optimizations.optimizations" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="pymasq.optimizations.optimizations.ExhaustiveSearch">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pymasq.optimizations.optimizations.</span></span><span class="sig-name descname"><span class="pre">ExhaustiveSearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_perms</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size_perms</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_best</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymasq.optimizations.optimizations.ExhaustiveSearch" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pymasq.optimizations._base.OptimizationBase</span></code></p>
<p>Standard brute-force optimization algorithm.</p>
<p>Exhuastive search is a pure, brute-force approach at finding an optimal mitigation strategy
based on the specified mitigations and evaluation metrics. This procedure will apply and evaluation
each permutation of the specified mitigations, thus guaranting to find the best, or optimal,
mitigation strategy. Exploring and evaluating each mitigation permutation can be computationally
expensive. The parameters, <cite>num_perms</cite> and <cite>size_perms</cite> can be specified to limit the number of
permutations explored and the length of each permutation, respectively. The search procedure is
terminated once <cite>num_perms</cite> is reached. Note that this restricts the exploration process in which
finding the optimial mitigation strategy can no longer be guaranteed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_perms</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of allowed permutations. If not set, all permutations up to
<cite>size_perms</cite> will be enumerated.
Note that this is may be computationally expensive and time consuming.</p></li>
<li><p><strong>size_perms</strong> (<em>int</em><em>, </em><em>optional</em>) – The maximum size of each permutation. If not set, all permutations will be
enumerated. Note that this is may be computationally expensive and time consuming.</p></li>
<li><p><strong>return_best</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>Default: False</em><em>)</em>) – Return the best target and fitness value found or the last one found.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Brute-force search or exhaustive search, also known as generate and test, is a very general
problem-solving technique and algorithmic paradigm that consists of systematically enumerating
all possible candidates for the solution and checking whether each candidate satisfies the
problem’s statement. <a href="#id15"><span class="problematic" id="id1">[1]_</span></a></p>
<p>If self.exit_on_error==False, then errors are written to the error_log column
of the returned logbook. Each row contains a list of errors.
Each item in a row’s list is of type exception.
An empty list indicates there were no errors.</p>
<p class="rubric">References</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Brute-force_search">https://en.wikipedia.org/wiki/Brute-force_search</a></p>
<p class="rubric">Examples</p>
<p>Import the dataset, evaluation metrics, mitigations, and optimization procedure</p>
<p>&gt;&gt; from pymasq.datasets import load_census
&gt;&gt; from pymasq.optimizations import ExhaustiveSearch
&gt;&gt; from pymasq.metrics import k_anon
&gt;&gt; from pymasq.mitigations import add_noise, map_values, truncate_values</p>
<p>Load the census dataset</p>
<p>&gt;&gt; df = load_census()</p>
<p>Set the evaluation function to be the k-anonymity risk metric and set
its respective parameters.</p>
<dl>
<dt>&gt;&gt; eval_fxns = {</dt><dd><blockquote>
<div><p>k_anon: {“weight”: 1., “params”: {“key_vars”: [“sex”]}}</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>Set the mitigation functions to be used during the optimization procedure and
set its respective parameters.</p>
<dl>
<dt>&gt;&gt; mit_fxns = [</dt><dd><blockquote>
<div><p>{“p”: 0.33, add_noise: {“col”: [“capital_gain”]}},
{“p”: 0.33, map_values: {“col”: [“education”], “method”: “md5”}},
{“p”: 0.34, truncate_values: {“col”: [“education”], “end_idx”: 3}}</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>Run the optimization procedure for 10 iterations with the size of each
permutation set to 2 and the number of allowed permutations to 4 (out of 6 possible).</p>
<dl>
<dt>&gt;&gt; search = ExhaustiveSearch(</dt><dd><blockquote>
<div><p>target=df, iters=10, mutations=mit_fxns, metrics=eval_fxns, size_perms=2, num_perms=4</p>
</div></blockquote>
<p>)</p>
</dd>
</dl>
<p>&gt;&gt; result_df, fit, logbook = search.optimize()
&gt;&gt; result_df</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pymasq.optimizations.optimizations.IncrementalSearch">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pymasq.optimizations.optimizations.</span></span><span class="sig-name descname"><span class="pre">IncrementalSearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retry</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymasq.optimizations.optimizations.IncrementalSearch" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pymasq.optimizations._base.OptimizationBase</span></code></p>
<p>Hill climbing optimization algorithm.</p>
<p>Incremental search applies a mitigation strategy on a target dataframe,
keeping only the mitigations which resulted in an improved fitness value and discarding all the rest.
Thus, this search procedure is primarily focused on exploitation, rather than exploration,
since it only accepts solutions that imrpove its fitness value. The search procedure is
terminated upon encountering a mitigation of that worsens its fitness value. A parameter,
<cite>retry</cite>, can be specified to allow the search procedure to continue even if it encounters a mitigation
which results in a worse fitness value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>retry</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>Default: 3</em><em>)</em>) – Number of times to continue an optimization procedure
even if a worse solution is found. Note that the standard hill-climbing
algorithm terminates as soon as one inferior solution is reached (e.g.
<cite>retry</cite> is <a href="#id2"><span class="problematic" id="id3">`</span></a>0).</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Hill climbing is a mathematical optimization technique which belongs to the family of local search.
It is an iterative algorithm that starts with an arbitrary solution to a problem, then attempts to
find a better solution by making an incremental change to the solution. If the change produces a
better solution, another incremental change is made to the new solution, and so on until no further
improvements can be found. <a href="#id16"><span class="problematic" id="id4">[1]_</span></a></p>
<p>If self.exit_on_error==False, then errors are written to the error_log column
of the returned logbook. Each row contains a list of errors.
Each item in a row’s list is of type exception.
An empty list indicates there were no errors.</p>
<p class="rubric">References</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Hill_climbing">https://en.wikipedia.org/wiki/Hill_climbing</a></p>
<p class="rubric">Examples</p>
<p>Import the dataset, evaluation metrics, mitigations, and optimization procedure</p>
<p>&gt;&gt; from pymasq.datasets import load_census
&gt;&gt; from pymasq.optimizations import IncrementalSearch
&gt;&gt; from pymasq.metrics import k_anon
&gt;&gt; from pymasq.mitigations import add_noise</p>
<p>Load the census dataset</p>
<p>&gt;&gt; df = load_census()</p>
<p>Set the evaluation function to be the k-anonymity risk metric and set
its respective parameters.</p>
<dl>
<dt>&gt;&gt; eval_fxns = {</dt><dd><blockquote>
<div><p>k_anon: {“weight”: 1., “params”: {“key_vars”: [“sex”]}}</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>Set the mitigation functions to be used during the optimization procedure and
set its respective parameters.</p>
<dl>
<dt>&gt;&gt; mit_fxns = [</dt><dd><blockquote>
<div><p>{“p”: 1., add_noise: {“col”: [“capital_gain”]}}</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>Run the optimization procedure for 10 iterations with 5 retries.</p>
<dl>
<dt>&gt;&gt; search = IncrementalSearch(</dt><dd><blockquote>
<div><p>target=df, iters=10, mutations=mit_fxns, metrics=eval_fxns, retry=5</p>
</div></blockquote>
<p>)</p>
</dd>
</dl>
<p>&gt;&gt; result_df, fit, logbook = search.optimize()
&gt;&gt; result_df</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pymasq.optimizations.optimizations.IterativeSearch">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pymasq.optimizations.optimizations.</span></span><span class="sig-name descname"><span class="pre">IterativeSearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_best</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymasq.optimizations.optimizations.IterativeSearch" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pymasq.optimizations._base.OptimizationBase</span></code></p>
<p>Iterative (sequential) optimization algorithm.</p>
<p>Iterative search consists solely of applying each of the selected mitigations
on a target dataframe. This search procedure is only concerned with exploration,
and not exploitation, since it does not keep track of the best mitigation strategy so far.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>return_best</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>Default: False</em><em>)</em>) – Return the best target and fitness value found or the last one found.</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The iterative method is a mathematical procedure that uses an initial guess to generate a
sequence of improving approximate solutions for a class of problems, in which the n-th
approximation is derived from the previous ones. A specific implementation of an iterative method,
including the termination criteria, is an algorithm of the iterative method. <a href="#id17"><span class="problematic" id="id5">[1]_</span></a></p>
<p>If self.exit_on_error==False, then errors are written to the error_log column
of the returned logbook. Each row contains a list of errors.
Each item in a row’s list is of type exception.
An empty list indicates there were no errors.</p>
<p class="rubric">References</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Iterative_method">https://en.wikipedia.org/wiki/Iterative_method</a></p>
<p class="rubric">Examples</p>
<p>Import the dataset, evaluation metrics, mitigations, and optimization procedure</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pymasq.datasets</span> <span class="kn">import</span> <span class="n">load_census</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pymasq.optimizations</span> <span class="kn">import</span> <span class="n">IterativeSearch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pymasq.metrics</span> <span class="kn">import</span> <span class="n">k_anon</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pymasq.mitigations</span> <span class="kn">import</span> <span class="n">add_noise</span>
</pre></div>
</div>
<p>Load the census dataset</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">load_census</span><span class="p">()</span>
</pre></div>
</div>
<p>Set the evaluation function to be the k-anonymity risk metric and set
its respective parameters.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">eval_fxns</span> <span class="o">=</span> <span class="p">{</span>
<span class="go">       k_anon: {&quot;weight&quot;: 1., &quot;params&quot;: {&quot;key_vars&quot;: [&quot;sex&quot;]}}</span>
<span class="go">   }</span>
</pre></div>
</div>
<p>Set the mitigation functions to be used during the optimization procedure and
set its respective parameters.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mit_fxns</span> <span class="o">=</span> <span class="p">[</span>
<span class="go">       {&quot;p&quot;: 1., add_noise: {&quot;col&quot;: [&quot;capital_gain&quot;]}}</span>
<span class="go">   ]</span>
</pre></div>
</div>
<p>Run the optimization procedure for 10 iterations.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">search</span> <span class="o">=</span> <span class="n">IterativeSearch</span><span class="p">(</span>
<span class="go">       target=df, iters=10, mutations=mit_fxns, metrics=eval_fxns</span>
<span class="go">   )</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result_df</span><span class="p">,</span> <span class="n">fit</span><span class="p">,</span> <span class="n">logbook</span> <span class="o">=</span> <span class="n">search</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result_df</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pymasq.optimizations.optimizations.StochasticSearch">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pymasq.optimizations.optimizations.</span></span><span class="sig-name descname"><span class="pre">StochasticSearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymasq.optimizations.optimizations.StochasticSearch" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pymasq.optimizations._base.OptimizationBase</span></code></p>
<p>Standard simulated annealing optimization algorithm.</p>
<p>Stochastic search balances exploration and exploitation, by applying a mitigation strategy
on a target dataframe and accepting both inferior and superior solutions. This procedure
keeps track of the overall best solution found, while also improving upon a current target dataframe.
This allows the search procedure to explore and evaluate sufficient candidate solutions, and
ensures the best mitigation strategy is found for the parameters specified. Two parameters,
<cite>alpha</cite> and <cite>temperature</cite>, specify the amount of exploration to perform. A high <cite>temperature</cite>
encourages the procedure to accept solutions that don’t improve the current fitness value for the
sake of exploration. The <cite>temperature</cite> is reduced over each iteration, following a standard
annealing schedule, parameterized by <cite>alpha</cite>. Once a low <cite>temperature</cite> is reached, the procedure
will only accept solutions that improved the current fitness value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>temperature</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>Default: 1.0</em><em>)</em>) – <p>Starting value for accepting inferior solutions. This value will decay
using the standard annealing schedule below.</p>
<div class="math notranslate nohighlight">
\[temperature := temperature x (1 - `alpha`)\]</div>
</p></li>
<li><p><strong>alpha</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>Default: 0.05</em><em>)</em>) – The <cite>temperature</cite> annealing/decay rate. High exploration is achieved when
<cite>alpha</cite> is low (near zero) and low exploration when <a href="#id6"><span class="problematic" id="id7">`</span></a>alpha is high (near one).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Simulated annealing (SA) is a probabilistic technique for approximating the global optimum of a given function.
Specifically, it is a metaheuristic to approximate global optimization in a large search space for an optimization problem.
It is often used when the search space is discrete (e.g., the traveling salesman problem). For problems where finding an
approximate global optimum is more important than finding a precise local optimum in a fixed amount of time,
simulated annealing may be preferable to alternatives such as gradient descent. [<a href="#id18"><span class="problematic" id="id19">1_</span></a>]</p>
<p>If self.exit_on_error==False, then errors are written to the error_log column
of the returned logbook. Each row contains a list of errors.
Each item in a row’s list is of type exception.
An empty list indicates there were no errors.</p>
<p class="rubric">References</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Simulated_annealing">https://en.wikipedia.org/wiki/Simulated_annealing</a></p>
<p class="rubric">Examples</p>
<p>Import the dataset, evaluation metrics, mitigations, and optimization procedure</p>
<p>&gt;&gt; from pymasq.datasets import load_census
&gt;&gt; from pymasq.optimizations import StochasticSearch
&gt;&gt; from pymasq.metrics import k_anon
&gt;&gt; from pymasq.mitigations import add_noise</p>
<p>Load the census dataset</p>
<p>&gt;&gt; df = load_census()</p>
<p>Set the evaluation function to be the k-anonymity risk metric and set
its respective parameters.</p>
<dl>
<dt>&gt;&gt; eval_fxns = {</dt><dd><blockquote>
<div><p>k_anon: {“weight”: 1., “params”: {“key_vars”: [“sex”]}}</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>Set the mitigation functions to be used during the optimization procedure and
set its respective parameters.</p>
<dl>
<dt>&gt;&gt; mit_fxns = [</dt><dd><blockquote>
<div><p>{“p”: 1., add_noise: {“col”: [“capital_gain”]}}</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>Run the optimization procedure for 10 iterations with an <cite>alpha</cite> decay of 0.25.</p>
<dl>
<dt>&gt;&gt; search = StochasticSearch(</dt><dd><blockquote>
<div><p>target=df, iters=10, mutations=mit_fxns, metrics=eval_fxns, alpha=0.25</p>
</div></blockquote>
<p>)</p>
</dd>
</dl>
<p>&gt;&gt; result_df, fit, logbook = search.optimize()
&gt;&gt; result_df</p>
</dd></dl>

</section>
<section id="module-pymasq.optimizations.utils">
<span id="pymasq-optimizations-utils-module"></span><h2>pymasq.optimizations.utils module<a class="headerlink" href="#module-pymasq.optimizations.utils" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="pymasq.optimizations.utils.apply_and_evaluate">
<span class="sig-prename descclassname"><span class="pre">pymasq.optimizations.utils.</span></span><span class="sig-name descname"><span class="pre">apply_and_evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pandas.core.frame.DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mutations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">pandas.core.frame.DataFrame</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">pandas.core.frame.DataFrame</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#pymasq.optimizations.utils.apply_and_evaluate" title="Permalink to this definition"></a></dt>
<dd><p>This helper method calls IterativeSearch in a specific fashion:
1) The given mitigation list is applied in order, without reuse or randomization
2) The given metrics are applied to the modified dataframe returned by step one.
In step 1, no metrics are applied. In step 2 no mitigations are applied. In other words,
the metrics are calculated once only: after all mitigations have been applied.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target</strong> (<em>pandas.DataFrame</em>) – The dataframe that will be manipulated and evaluated.</p></li>
<li><p><strong>mutations</strong> (<em>List</em><em>[</em><em>Dict</em><em>]</em>) – <p>List of mutations (e.g., mitigations) to use when manipulating
the <cite>target</cite> dataframe. Each mutation should be defined as a
separate <cite>dict</cite> in the <cite>list</cite>, where the two top-level keys are the
names of the <cite>pymasq</cite> mitigation to use or the function itself
(e.g., <cite>“add_noise”</cite> or <cite>pymasq.mitigations.add_noise</cite>), and
<cite>p</cite>, which defines the probability of choosing that specific mitigation.</p>
<p>The values of the function keys must also be a <cite>dict</cite> with the key-value pairs
that will parameterize each respective mitigation function.</p>
<p>The values of each probability key must be an <cite>int</cite> or <cite>float</cite>.
For <cite>float</cite> values, each probability should be rounded to 2 decimal places
and the sum of each probability must sum to 1. Note that an <cite>int</cite>
value will imply that there is only 1 mitigation to be used.</p>
<p>Note that mitigations are applied even if they reduce the fitness score calculated
by the given metric.</p>
</p></li>
<li><p><strong>metrics</strong> (<em>Dict</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>Callable</em><em>]</em><em>, </em><em>Dict</em><em>]</em>) – <p>Functions used to evaluate <cite>target</cite> dataframe. The top-level keys should
be the names of the <cite>pymasq</cite> metric to use or the function itself (e.g.,
<cite>“auc_score”</cite> or <cite>pymasq.metrics.auc_score</cite>).</p>
<p>The values of the function keys must also be a <cite>dict</cite> with <cite>weight</cite> and
<cite>params</cite> as keys. The weight key’s value must be a float, and the <cite>params</cite>
key’s value must be a <cite>dict</cite> with the key-value pairs that will parameterize
each respective metrics function.</p>
</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Set the verbosity level throughout the optimization procedure. (Default: 0)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>pd.DataFrame</em> – The modified target</p></li>
<li><p><em>float</em> – The fitness value</p></li>
<li><p><em>list</em> – The log of mutations applied</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pymasq.datasets</span> <span class="kn">import</span> <span class="n">load_census</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pymasq.utils</span> <span class="kn">import</span> <span class="n">apply_and_evaluate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pymasq.metrics</span> <span class="kn">import</span> <span class="n">k_anon</span><span class="p">,</span> <span class="n">propensity_score</span>
</pre></div>
</div>
<p>Load the census dataset</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">load_census</span><span class="p">()</span>
</pre></div>
</div>
<p>Set the evaluation function to be the k-anonymity risk metric and set
its respective parameters.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">eval_fxns</span> <span class="o">=</span> <span class="p">{</span>
<span class="go">    k_anon: {&quot;params&quot;: {&quot;key_vars&quot;: [&quot;sex&quot;]}},</span>
<span class="go">    propensity_score: {&quot;params&quot;: {&quot;sensitive_col&quot;: &quot;age&quot;,&quot;method&quot;:&quot;larscv&quot;,&quot;preprocessor&quot;:&quot;label_encode&quot;}}</span>
<span class="go">    }</span>
</pre></div>
</div>
<p>Set the mitigation functions to be applied.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mit_fxns</span> <span class="o">=</span> <span class="p">[</span>
<span class="go">    {&quot;hashing&quot;: {&quot;cols&quot;: [&quot;education&quot;]}},</span>
<span class="go">    {&quot;add_noise&quot;: {&quot;cols&quot;: [&quot;age&quot;],&quot;method&quot;:&quot;additive&quot;, &quot;magnitude&quot;: 100}}</span>
<span class="go">   ]</span>
</pre></div>
</div>
<p>Execute.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mod_df</span><span class="p">,</span> <span class="n">fitness</span><span class="p">,</span> <span class="n">log</span> <span class="o">=</span> <span class="n">apply_and_evaluate</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">mit_fxns</span><span class="p">,</span> <span class="n">eval_fxns</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="module-pymasq.optimizations">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-pymasq.optimizations" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="pymasq.optimizations.ExhaustiveSearch">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pymasq.optimizations.</span></span><span class="sig-name descname"><span class="pre">ExhaustiveSearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_perms</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size_perms</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_best</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymasq.optimizations.ExhaustiveSearch" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pymasq.optimizations._base.OptimizationBase</span></code></p>
<p>Standard brute-force optimization algorithm.</p>
<p>Exhuastive search is a pure, brute-force approach at finding an optimal mitigation strategy
based on the specified mitigations and evaluation metrics. This procedure will apply and evaluation
each permutation of the specified mitigations, thus guaranting to find the best, or optimal,
mitigation strategy. Exploring and evaluating each mitigation permutation can be computationally
expensive. The parameters, <cite>num_perms</cite> and <cite>size_perms</cite> can be specified to limit the number of
permutations explored and the length of each permutation, respectively. The search procedure is
terminated once <cite>num_perms</cite> is reached. Note that this restricts the exploration process in which
finding the optimial mitigation strategy can no longer be guaranteed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_perms</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of allowed permutations. If not set, all permutations up to
<cite>size_perms</cite> will be enumerated.
Note that this is may be computationally expensive and time consuming.</p></li>
<li><p><strong>size_perms</strong> (<em>int</em><em>, </em><em>optional</em>) – The maximum size of each permutation. If not set, all permutations will be
enumerated. Note that this is may be computationally expensive and time consuming.</p></li>
<li><p><strong>return_best</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>Default: False</em><em>)</em>) – Return the best target and fitness value found or the last one found.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Brute-force search or exhaustive search, also known as generate and test, is a very general
problem-solving technique and algorithmic paradigm that consists of systematically enumerating
all possible candidates for the solution and checking whether each candidate satisfies the
problem’s statement. <a href="#id20"><span class="problematic" id="id8">[1]_</span></a></p>
<p>If self.exit_on_error==False, then errors are written to the error_log column
of the returned logbook. Each row contains a list of errors.
Each item in a row’s list is of type exception.
An empty list indicates there were no errors.</p>
<p class="rubric">References</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Brute-force_search">https://en.wikipedia.org/wiki/Brute-force_search</a></p>
<p class="rubric">Examples</p>
<p>Import the dataset, evaluation metrics, mitigations, and optimization procedure</p>
<p>&gt;&gt; from pymasq.datasets import load_census
&gt;&gt; from pymasq.optimizations import ExhaustiveSearch
&gt;&gt; from pymasq.metrics import k_anon
&gt;&gt; from pymasq.mitigations import add_noise, map_values, truncate_values</p>
<p>Load the census dataset</p>
<p>&gt;&gt; df = load_census()</p>
<p>Set the evaluation function to be the k-anonymity risk metric and set
its respective parameters.</p>
<dl>
<dt>&gt;&gt; eval_fxns = {</dt><dd><blockquote>
<div><p>k_anon: {“weight”: 1., “params”: {“key_vars”: [“sex”]}}</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>Set the mitigation functions to be used during the optimization procedure and
set its respective parameters.</p>
<dl>
<dt>&gt;&gt; mit_fxns = [</dt><dd><blockquote>
<div><p>{“p”: 0.33, add_noise: {“col”: [“capital_gain”]}},
{“p”: 0.33, map_values: {“col”: [“education”], “method”: “md5”}},
{“p”: 0.34, truncate_values: {“col”: [“education”], “end_idx”: 3}}</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>Run the optimization procedure for 10 iterations with the size of each
permutation set to 2 and the number of allowed permutations to 4 (out of 6 possible).</p>
<dl>
<dt>&gt;&gt; search = ExhaustiveSearch(</dt><dd><blockquote>
<div><p>target=df, iters=10, mutations=mit_fxns, metrics=eval_fxns, size_perms=2, num_perms=4</p>
</div></blockquote>
<p>)</p>
</dd>
</dl>
<p>&gt;&gt; result_df, fit, logbook = search.optimize()
&gt;&gt; result_df</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pymasq.optimizations.IncrementalSearch">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pymasq.optimizations.</span></span><span class="sig-name descname"><span class="pre">IncrementalSearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retry</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymasq.optimizations.IncrementalSearch" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pymasq.optimizations._base.OptimizationBase</span></code></p>
<p>Hill climbing optimization algorithm.</p>
<p>Incremental search applies a mitigation strategy on a target dataframe,
keeping only the mitigations which resulted in an improved fitness value and discarding all the rest.
Thus, this search procedure is primarily focused on exploitation, rather than exploration,
since it only accepts solutions that imrpove its fitness value. The search procedure is
terminated upon encountering a mitigation of that worsens its fitness value. A parameter,
<cite>retry</cite>, can be specified to allow the search procedure to continue even if it encounters a mitigation
which results in a worse fitness value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>retry</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>Default: 3</em><em>)</em>) – Number of times to continue an optimization procedure
even if a worse solution is found. Note that the standard hill-climbing
algorithm terminates as soon as one inferior solution is reached (e.g.
<cite>retry</cite> is <a href="#id9"><span class="problematic" id="id10">`</span></a>0).</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Hill climbing is a mathematical optimization technique which belongs to the family of local search.
It is an iterative algorithm that starts with an arbitrary solution to a problem, then attempts to
find a better solution by making an incremental change to the solution. If the change produces a
better solution, another incremental change is made to the new solution, and so on until no further
improvements can be found. <a href="#id21"><span class="problematic" id="id11">[1]_</span></a></p>
<p>If self.exit_on_error==False, then errors are written to the error_log column
of the returned logbook. Each row contains a list of errors.
Each item in a row’s list is of type exception.
An empty list indicates there were no errors.</p>
<p class="rubric">References</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Hill_climbing">https://en.wikipedia.org/wiki/Hill_climbing</a></p>
<p class="rubric">Examples</p>
<p>Import the dataset, evaluation metrics, mitigations, and optimization procedure</p>
<p>&gt;&gt; from pymasq.datasets import load_census
&gt;&gt; from pymasq.optimizations import IncrementalSearch
&gt;&gt; from pymasq.metrics import k_anon
&gt;&gt; from pymasq.mitigations import add_noise</p>
<p>Load the census dataset</p>
<p>&gt;&gt; df = load_census()</p>
<p>Set the evaluation function to be the k-anonymity risk metric and set
its respective parameters.</p>
<dl>
<dt>&gt;&gt; eval_fxns = {</dt><dd><blockquote>
<div><p>k_anon: {“weight”: 1., “params”: {“key_vars”: [“sex”]}}</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>Set the mitigation functions to be used during the optimization procedure and
set its respective parameters.</p>
<dl>
<dt>&gt;&gt; mit_fxns = [</dt><dd><blockquote>
<div><p>{“p”: 1., add_noise: {“col”: [“capital_gain”]}}</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>Run the optimization procedure for 10 iterations with 5 retries.</p>
<dl>
<dt>&gt;&gt; search = IncrementalSearch(</dt><dd><blockquote>
<div><p>target=df, iters=10, mutations=mit_fxns, metrics=eval_fxns, retry=5</p>
</div></blockquote>
<p>)</p>
</dd>
</dl>
<p>&gt;&gt; result_df, fit, logbook = search.optimize()
&gt;&gt; result_df</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pymasq.optimizations.IterativeSearch">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pymasq.optimizations.</span></span><span class="sig-name descname"><span class="pre">IterativeSearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_best</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymasq.optimizations.IterativeSearch" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pymasq.optimizations._base.OptimizationBase</span></code></p>
<p>Iterative (sequential) optimization algorithm.</p>
<p>Iterative search consists solely of applying each of the selected mitigations
on a target dataframe. This search procedure is only concerned with exploration,
and not exploitation, since it does not keep track of the best mitigation strategy so far.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>return_best</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>Default: False</em><em>)</em>) – Return the best target and fitness value found or the last one found.</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The iterative method is a mathematical procedure that uses an initial guess to generate a
sequence of improving approximate solutions for a class of problems, in which the n-th
approximation is derived from the previous ones. A specific implementation of an iterative method,
including the termination criteria, is an algorithm of the iterative method. <a href="#id22"><span class="problematic" id="id12">[1]_</span></a></p>
<p>If self.exit_on_error==False, then errors are written to the error_log column
of the returned logbook. Each row contains a list of errors.
Each item in a row’s list is of type exception.
An empty list indicates there were no errors.</p>
<p class="rubric">References</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Iterative_method">https://en.wikipedia.org/wiki/Iterative_method</a></p>
<p class="rubric">Examples</p>
<p>Import the dataset, evaluation metrics, mitigations, and optimization procedure</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pymasq.datasets</span> <span class="kn">import</span> <span class="n">load_census</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pymasq.optimizations</span> <span class="kn">import</span> <span class="n">IterativeSearch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pymasq.metrics</span> <span class="kn">import</span> <span class="n">k_anon</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pymasq.mitigations</span> <span class="kn">import</span> <span class="n">add_noise</span>
</pre></div>
</div>
<p>Load the census dataset</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">load_census</span><span class="p">()</span>
</pre></div>
</div>
<p>Set the evaluation function to be the k-anonymity risk metric and set
its respective parameters.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">eval_fxns</span> <span class="o">=</span> <span class="p">{</span>
<span class="go">       k_anon: {&quot;weight&quot;: 1., &quot;params&quot;: {&quot;key_vars&quot;: [&quot;sex&quot;]}}</span>
<span class="go">   }</span>
</pre></div>
</div>
<p>Set the mitigation functions to be used during the optimization procedure and
set its respective parameters.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mit_fxns</span> <span class="o">=</span> <span class="p">[</span>
<span class="go">       {&quot;p&quot;: 1., add_noise: {&quot;col&quot;: [&quot;capital_gain&quot;]}}</span>
<span class="go">   ]</span>
</pre></div>
</div>
<p>Run the optimization procedure for 10 iterations.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">search</span> <span class="o">=</span> <span class="n">IterativeSearch</span><span class="p">(</span>
<span class="go">       target=df, iters=10, mutations=mit_fxns, metrics=eval_fxns</span>
<span class="go">   )</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result_df</span><span class="p">,</span> <span class="n">fit</span><span class="p">,</span> <span class="n">logbook</span> <span class="o">=</span> <span class="n">search</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result_df</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pymasq.optimizations.StochasticSearch">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pymasq.optimizations.</span></span><span class="sig-name descname"><span class="pre">StochasticSearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymasq.optimizations.StochasticSearch" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pymasq.optimizations._base.OptimizationBase</span></code></p>
<p>Standard simulated annealing optimization algorithm.</p>
<p>Stochastic search balances exploration and exploitation, by applying a mitigation strategy
on a target dataframe and accepting both inferior and superior solutions. This procedure
keeps track of the overall best solution found, while also improving upon a current target dataframe.
This allows the search procedure to explore and evaluate sufficient candidate solutions, and
ensures the best mitigation strategy is found for the parameters specified. Two parameters,
<cite>alpha</cite> and <cite>temperature</cite>, specify the amount of exploration to perform. A high <cite>temperature</cite>
encourages the procedure to accept solutions that don’t improve the current fitness value for the
sake of exploration. The <cite>temperature</cite> is reduced over each iteration, following a standard
annealing schedule, parameterized by <cite>alpha</cite>. Once a low <cite>temperature</cite> is reached, the procedure
will only accept solutions that improved the current fitness value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>temperature</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>Default: 1.0</em><em>)</em>) – <p>Starting value for accepting inferior solutions. This value will decay
using the standard annealing schedule below.</p>
<div class="math notranslate nohighlight">
\[temperature := temperature x (1 - `alpha`)\]</div>
</p></li>
<li><p><strong>alpha</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>Default: 0.05</em><em>)</em>) – The <cite>temperature</cite> annealing/decay rate. High exploration is achieved when
<cite>alpha</cite> is low (near zero) and low exploration when <a href="#id13"><span class="problematic" id="id14">`</span></a>alpha is high (near one).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Simulated annealing (SA) is a probabilistic technique for approximating the global optimum of a given function.
Specifically, it is a metaheuristic to approximate global optimization in a large search space for an optimization problem.
It is often used when the search space is discrete (e.g., the traveling salesman problem). For problems where finding an
approximate global optimum is more important than finding a precise local optimum in a fixed amount of time,
simulated annealing may be preferable to alternatives such as gradient descent. [<a href="#id23"><span class="problematic" id="id24">1_</span></a>]</p>
<p>If self.exit_on_error==False, then errors are written to the error_log column
of the returned logbook. Each row contains a list of errors.
Each item in a row’s list is of type exception.
An empty list indicates there were no errors.</p>
<p class="rubric">References</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Simulated_annealing">https://en.wikipedia.org/wiki/Simulated_annealing</a></p>
<p class="rubric">Examples</p>
<p>Import the dataset, evaluation metrics, mitigations, and optimization procedure</p>
<p>&gt;&gt; from pymasq.datasets import load_census
&gt;&gt; from pymasq.optimizations import StochasticSearch
&gt;&gt; from pymasq.metrics import k_anon
&gt;&gt; from pymasq.mitigations import add_noise</p>
<p>Load the census dataset</p>
<p>&gt;&gt; df = load_census()</p>
<p>Set the evaluation function to be the k-anonymity risk metric and set
its respective parameters.</p>
<dl>
<dt>&gt;&gt; eval_fxns = {</dt><dd><blockquote>
<div><p>k_anon: {“weight”: 1., “params”: {“key_vars”: [“sex”]}}</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>Set the mitigation functions to be used during the optimization procedure and
set its respective parameters.</p>
<dl>
<dt>&gt;&gt; mit_fxns = [</dt><dd><blockquote>
<div><p>{“p”: 1., add_noise: {“col”: [“capital_gain”]}}</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>Run the optimization procedure for 10 iterations with an <cite>alpha</cite> decay of 0.25.</p>
<dl>
<dt>&gt;&gt; search = StochasticSearch(</dt><dd><blockquote>
<div><p>target=df, iters=10, mutations=mit_fxns, metrics=eval_fxns, alpha=0.25</p>
</div></blockquote>
<p>)</p>
</dd>
</dl>
<p>&gt;&gt; result_df, fit, logbook = search.optimize()
&gt;&gt; result_df</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymasq.optimizations.apply_and_evaluate">
<span class="sig-prename descclassname"><span class="pre">pymasq.optimizations.</span></span><span class="sig-name descname"><span class="pre">apply_and_evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pandas.core.frame.DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mutations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">pandas.core.frame.DataFrame</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">pandas.core.frame.DataFrame</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#pymasq.optimizations.apply_and_evaluate" title="Permalink to this definition"></a></dt>
<dd><p>This helper method calls IterativeSearch in a specific fashion:
1) The given mitigation list is applied in order, without reuse or randomization
2) The given metrics are applied to the modified dataframe returned by step one.
In step 1, no metrics are applied. In step 2 no mitigations are applied. In other words,
the metrics are calculated once only: after all mitigations have been applied.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target</strong> (<em>pandas.DataFrame</em>) – The dataframe that will be manipulated and evaluated.</p></li>
<li><p><strong>mutations</strong> (<em>List</em><em>[</em><em>Dict</em><em>]</em>) – <p>List of mutations (e.g., mitigations) to use when manipulating
the <cite>target</cite> dataframe. Each mutation should be defined as a
separate <cite>dict</cite> in the <cite>list</cite>, where the two top-level keys are the
names of the <cite>pymasq</cite> mitigation to use or the function itself
(e.g., <cite>“add_noise”</cite> or <cite>pymasq.mitigations.add_noise</cite>), and
<cite>p</cite>, which defines the probability of choosing that specific mitigation.</p>
<p>The values of the function keys must also be a <cite>dict</cite> with the key-value pairs
that will parameterize each respective mitigation function.</p>
<p>The values of each probability key must be an <cite>int</cite> or <cite>float</cite>.
For <cite>float</cite> values, each probability should be rounded to 2 decimal places
and the sum of each probability must sum to 1. Note that an <cite>int</cite>
value will imply that there is only 1 mitigation to be used.</p>
<p>Note that mitigations are applied even if they reduce the fitness score calculated
by the given metric.</p>
</p></li>
<li><p><strong>metrics</strong> (<em>Dict</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>Callable</em><em>]</em><em>, </em><em>Dict</em><em>]</em>) – <p>Functions used to evaluate <cite>target</cite> dataframe. The top-level keys should
be the names of the <cite>pymasq</cite> metric to use or the function itself (e.g.,
<cite>“auc_score”</cite> or <cite>pymasq.metrics.auc_score</cite>).</p>
<p>The values of the function keys must also be a <cite>dict</cite> with <cite>weight</cite> and
<cite>params</cite> as keys. The weight key’s value must be a float, and the <cite>params</cite>
key’s value must be a <cite>dict</cite> with the key-value pairs that will parameterize
each respective metrics function.</p>
</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Set the verbosity level throughout the optimization procedure. (Default: 0)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>pd.DataFrame</em> – The modified target</p></li>
<li><p><em>float</em> – The fitness value</p></li>
<li><p><em>list</em> – The log of mutations applied</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pymasq.datasets</span> <span class="kn">import</span> <span class="n">load_census</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pymasq.utils</span> <span class="kn">import</span> <span class="n">apply_and_evaluate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pymasq.metrics</span> <span class="kn">import</span> <span class="n">k_anon</span><span class="p">,</span> <span class="n">propensity_score</span>
</pre></div>
</div>
<p>Load the census dataset</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">load_census</span><span class="p">()</span>
</pre></div>
</div>
<p>Set the evaluation function to be the k-anonymity risk metric and set
its respective parameters.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">eval_fxns</span> <span class="o">=</span> <span class="p">{</span>
<span class="go">    k_anon: {&quot;params&quot;: {&quot;key_vars&quot;: [&quot;sex&quot;]}},</span>
<span class="go">    propensity_score: {&quot;params&quot;: {&quot;sensitive_col&quot;: &quot;age&quot;,&quot;method&quot;:&quot;larscv&quot;,&quot;preprocessor&quot;:&quot;label_encode&quot;}}</span>
<span class="go">    }</span>
</pre></div>
</div>
<p>Set the mitigation functions to be applied.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mit_fxns</span> <span class="o">=</span> <span class="p">[</span>
<span class="go">    {&quot;hashing&quot;: {&quot;cols&quot;: [&quot;education&quot;]}},</span>
<span class="go">    {&quot;add_noise&quot;: {&quot;cols&quot;: [&quot;age&quot;],&quot;method&quot;:&quot;additive&quot;, &quot;magnitude&quot;: 100}}</span>
<span class="go">   ]</span>
</pre></div>
</div>
<p>Execute.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mod_df</span><span class="p">,</span> <span class="n">fitness</span><span class="p">,</span> <span class="n">log</span> <span class="o">=</span> <span class="n">apply_and_evaluate</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">mit_fxns</span><span class="p">,</span> <span class="n">eval_fxns</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MITLL.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>