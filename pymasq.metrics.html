<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pymasq.metrics package &mdash; pymasq 1.0 documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> pymasq
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="readme.html">README</a></li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">pymasq</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">pymasq</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>pymasq.metrics package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/pymasq.metrics.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="pymasq-metrics-package">
<h1>pymasq.metrics package<a class="headerlink" href="#pymasq-metrics-package" title="Permalink to this headline"></a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline"></a></h2>
</section>
<section id="module-pymasq.metrics.auc_scores">
<span id="pymasq-metrics-auc-scores-module"></span><h2>pymasq.metrics.auc_scores module<a class="headerlink" href="#module-pymasq.metrics.auc_scores" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt id="pymasq.metrics.auc_scores.auc_score">
<code class="sig-prename descclassname">pymasq.metrics.auc_scores.</code><code class="sig-name descname">auc_score</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">orig_df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">mod_df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">method</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">preprocessor</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'embeddings'</span></em>, <em class="sig-param"><span class="n">modeling_task</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">cache_location</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">absolute_risk</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">retrain</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#pymasq.metrics.auc_scores.auc_score" title="Permalink to this definition"></a></dt>
<dd><p>Calculates the AUC score for the provided original and modified dataframes given the target
column name and cache folder.</p>
<p>AUC Score trains a classifier based on orig_df in order to predict the values in sensitive_col from
the values in the other columns. It then applies the classifier to the mod_df — that is, based on the
values in the other columns in mod_df, it uses the trained classifier to predict the values in the sensitve_column
of mod_df. The AUC score for the prediction is returned as the score.</p>
<p>How is this different than propensity? Propensity stacks the orig_df and mod_df in one combined df. It then adds a
0/1 column that specifies the class of the row original. The combined frame is split into train and test. The classifer
is trained to determine the class of each row. The classifier is then tested. Propensity is the AUC score for the prediction.)</p>
<dl>
<dt>AUC_SCORE:</dt><dd><dl class="simple">
<dt>Train(orig, predict[sensitive]) -&gt;</dt><dd><ul class="simple">
<li><p>Test(orig, predict[sensity])</p></li>
<li><p>Test(mod, predict[sensity])</p></li>
</ul>
</dd>
</dl>
<p>Difference in test performance is AUC_Score</p>
</dd>
<dt>PROPENSITY:</dt><dd><p>combined = orig+mod with new column
traindf = x% of combined
testdf = (1-x)% of combined
Classifer(traindf, predict[new column])</p>
<blockquote>
<div><ul class="simple">
<li><p>Test(testdf, predict[new column])</p></li>
</ul>
</div></blockquote>
<p>Propensity of the area under the curve from Test()ing</p>
</dd>
</dl>
<p>1.0 indicates high disimilarity between orig_df and mod_df
0.0 indicates high similarity between orig_df and mod_df</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>orig_df</strong> (<em>pd.Dataframe</em>) – Data frame containing the original unaltered data</p></li>
<li><p><strong>mod_df</strong> (<em>pd.Dataframe</em>) – Data frame containing the modified data after application of mitigation(s)</p></li>
<li><p><strong>sensitive_col</strong> (<em>str</em>) – String of sensitive column name in the data frame that contains labels</p></li>
<li><p><strong>method</strong> (<em>str</em>) – <p>The classifier method to use. There are several options.
- “encv” denotes the sklearn ElasticNetCV regressor
- “larscv” denotes the sklearn LarsCV regressor
- “rfreg” denotes the sklearn Random Forest regressor
- “logreg” denotes the sklearn Logisitc RegressionCV classifier
- “rfclass” denotes the sklearn Random Forest classifier
- “tpotreg” denotes the use of a pre-trained TPOT regressor. To pre-train</p>
<blockquote>
<div><p>TPOT call pymasq.models.TpotRegressor.train(), which will save the trained
model to a cache location. If a different than the default pymasq location is
used, specify the path in the “cache_location” argument. If method is “tpot”,
then “tpot_fname” should be passed as a named keyword argument.</p>
</div></blockquote>
<ul>
<li><p>”tpotclass” denotes the use of a pre-trained TPOT classifer. To pre-train
TPOT call pymasq.models.TpotClassifier.train(), which will save the trained
model to a cache location. If a different than the default pymasq location is
used, specify the path in the “cache_location” argument. If method is “tpot”,
then “tpot_fname” should be passed as a named keyword argument.</p></li>
</ul>
</p></li>
<li><p><strong>preprocessor</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>Default: 'embeddings'</em><em>)</em>) – The pymasq preprocessor to use. There are several options.
- ‘embeddings’: advanced processing of numeric and categorical data.
- ‘label_encode’: skLearn-based encoding of categorical data only
- None: the dataframes are not processed and assumed ready for use by a classifier</p></li>
<li><p><strong>modeling_task</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>Default: None</em><em>)</em>) – Type of modeling used to prepare model and preprocessor, if not set then it
will calculated from the sensitive column</p></li>
<li><p><strong>cache_location</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>Default: None</em><em>)</em>) – String for the directory path to the cache for the current TPOT data</p></li>
<li><p><strong>absolute_risk</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>Default: False</em><em>)</em>) – Boolean flag that, when true, calculates the absolute risk score.</p></li>
<li><p><strong>retrain</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>Default: True</em><em>)</em>) – Whether to ignore cached training data</p></li>
<li><p><strong>**kwargs</strong> (<em>Dict</em><em>[</em><em>Any</em><em>, </em><em>Any</em><em>]</em>) – Values for algorithm-specific headers to be added to called method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The auc score, as absolute risk or as a risk score</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-pymasq.metrics.risk_scores">
<span id="pymasq-metrics-risk-scores-module"></span><h2>pymasq.metrics.risk_scores module<a class="headerlink" href="#module-pymasq.metrics.risk_scores" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt id="pymasq.metrics.risk_scores.beta_likeness">
<code class="sig-prename descclassname">pymasq.metrics.risk_scores.</code><code class="sig-name descname">beta_likeness</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">beta</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>int<span class="p">, </span>float<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">qi</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">enhanced</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">bool_return</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em><span class="sig-paren">)</span> &#x2192; Union<span class="p">[</span>bool<span class="p">, </span>float<span class="p">]</span><a class="headerlink" href="#pymasq.metrics.risk_scores.beta_likeness" title="Permalink to this definition"></a></dt>
<dd><p>Determines the percent of entries in the data that do not satisfy beta-likeness. If
bool_return is set to True, returns True if the entire dataset satisfies beta-likeness for a
given beta value, False otherwise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>pd.DataFrame</em>) – A data frame with data that beta-likeness is being measured for</p></li>
<li><p><strong>sensitive_col</strong> (<em>str</em>) – The name of only one column containing the data that is being obscured by mitigations</p></li>
<li><p><strong>beta</strong> (<em>float</em><em> (</em><em>&gt;0</em><em>)</em><em>, </em><em>optional</em>) – The tolerance threshold for the increase in confidence of a certain sensitive attribute,
in relative difference terms, for SAs in an equivalence class versus the total population
(Default: 1.0)</p></li>
<li><p><strong>qi</strong> (<em>List</em><em>, </em><em>optional</em>) – Columns to be considered as the quasi-indicators. If not provided it is assumed that all columns
but the sensitive column are the quasi-indicators.
(Default: None)</p></li>
<li><p><strong>enhanced</strong> (<em>bool</em><em>, </em><em>optional</em>) – Should the function run enhanced beta-likeness instead of basic beta-likeness.
(Default: True)</p></li>
<li><p><strong>bool_return</strong> (<em>bool</em><em>, </em><em>optional</em>) – Should the function return a boolean indicating True if beta-likeness is satisfied/False
if beta-likeness is not satisfied.
(Default: False)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>bool</em> – If the <cite>bool_return</cite> flag is set to True, the function will return True if the supplied dataframe
satisfies beta likeness for the supplied sensitive column and beta value</p></li>
<li><p><em>float</em> – The proportion of the rows that fail beta-likeness</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference internal" href="pymasq.errors.html#pymasq.errors.InputError" title="pymasq.errors.InputError"><strong>InputError</strong></a> – This error is raised when a <cite>beta</cite> value of &lt;= 0 is supplied.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.risk_scores.indiv_risk">
<code class="sig-prename descclassname">pymasq.metrics.risk_scores.</code><code class="sig-name descname">indiv_risk</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>int<span class="p">, </span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">quasi_cols</span><span class="p">:</span> <span class="n">List<span class="p">[</span>Union<span class="p">[</span>int<span class="p">, </span>str<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">method</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'approx'</span></em>, <em class="sig-param"><span class="n">weights</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>Union<span class="p">[</span>int<span class="p">, </span>float<span class="p">]</span><span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">qual</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>int<span class="p">, </span>float<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymasq.metrics.risk_scores.indiv_risk" title="Permalink to this definition"></a></dt>
<dd><p>Calculate the individual risk each value contributes in re-identifying sensitve variable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>DataFrame</em><em>, </em><em>Series</em><em>, or </em><em>array_like</em>) – The data to be modified.</p></li>
<li><p><strong>sensitive_col</strong> (<em>str</em><em> or </em><em>int</em>) – Column whos relationship to other columns needs to be obfuscated.</p></li>
<li><p><strong>quasi_cols</strong> (<em>list</em>) – Columns to consider when calculating individual risk of re-identifying <cite>sensitive_col</cite>.</p></li>
<li><p><strong>method</strong> (<em>{'approx'</em><em>, </em><em>'exact'}</em><em> (</em><em>Default: 'approx'</em><em>)</em>) – Precision for calculating the individual risk of each value.</p></li>
<li><p><strong>weights</strong> (<em>list</em><em>, </em><em>optional</em><em> (</em><em>Default: None</em><em>)</em>) – Proportion of rows with the same combination of values in <cite>data</cite> for
each row in <cite>data</cite>, only to be used if <cite>data</cite> is a sample/subset of a larger dataset.
If None, <cite>weights</cite> will be a unit vector indicating that <cite>data</cite> is the full population.</p></li>
<li><p><strong>qual</strong> (<em>float</em><em> (</em><em>0</em><em>, </em><em>1</em><em>]</em><em>, </em><em>optional</em><em> (</em><em>Default: 1</em><em>)</em>) – Perceived quality of frequency counts to act as a final correction factor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A DataFrame with the individual risk values of each row.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>DataFrame</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>InputError:</strong> – Raised when invalid arguments are passed.</p></li>
<li><p><a class="reference internal" href="pymasq.errors.html#pymasq.errors.NotInRangeError" title="pymasq.errors.NotInRangeError"><strong>NotInRangeError</strong></a> – Raised if <cite>risk_threshold</cite> is outside the interval [0, 1].</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.risk_scores.indiv_risk_approx">
<code class="sig-prename descclassname">pymasq.metrics.risk_scores.</code><code class="sig-name descname">indiv_risk_approx</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">fk</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>int<span class="p">, </span>float<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">Fk</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>int<span class="p">, </span>float<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#pymasq.metrics.risk_scores.indiv_risk_approx" title="Permalink to this definition"></a></dt>
<dd><p>calculates the approximate individual risk</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fk</strong> (<em>int</em><em> or </em><em>float</em>) – the sample frequency of the row’s combination of quasi-identifier values</p></li>
<li><p><strong>Fk</strong> (<em>int</em><em> or </em><em>float</em>) – the population frequence of the row’s combination of quasi-identifier values</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>risk score in [0, 1]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>TODO</p>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.risk_scores.indiv_risk_exact">
<code class="sig-prename descclassname">pymasq.metrics.risk_scores.</code><code class="sig-name descname">indiv_risk_exact</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">fk</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">Fk</span><span class="p">:</span> <span class="n">float</span></em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#pymasq.metrics.risk_scores.indiv_risk_exact" title="Permalink to this definition"></a></dt>
<dd><p>calculates the exact individual risk</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fk</strong> (<em>int</em>) – the sample frequency of the row’s combination of quasi-identifier values</p></li>
<li><p><strong>Fk</strong> (<em>int</em>) – the population frequence of the row’s combination of quasi-identifier values</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>risk score in [0, 1]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>TODO</p>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.risk_scores.is_beta_like">
<code class="sig-prename descclassname">pymasq.metrics.risk_scores.</code><code class="sig-name descname">is_beta_like</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">beta</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">qi</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">enhanced</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#pymasq.metrics.risk_scores.is_beta_like" title="Permalink to this definition"></a></dt>
<dd><p>Determines if the beta-likeness is satisfied for parameter beta</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>pd.DataFrame</em>) – A data frame with data that beta-likeness is being measured for</p></li>
<li><p><strong>sensitive_col</strong> (<em>str</em>) – The name of only one column containing the data that is being obscured by mitigations</p></li>
<li><p><strong>beta</strong> (<em>float</em><em> (</em><em>&gt;0</em><em>)</em><em>, </em><em>optional</em>) – The tolerance threshold for the increase in confidence of a certain sensitive attribute,
in relative difference terms, for SAs in an equivalence class versus the total population
(Default: 1.0)</p></li>
<li><p><strong>qi</strong> (<em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – Columns to be considered as the quasi-indicators. If not provided it is assumed that all columns
but the sensitive column are the quasi-indicators.
(Default: None)</p></li>
<li><p><strong>enhanced</strong> (<em>bool</em><em>, </em><em>optional</em>) – Should the function run enhanced beta-likeness instead of basic beta-likeness.
(Default: True)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> – Whether the dataset satisfies beta-likeness or not.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.risk_scores.is_k_anon">
<code class="sig-prename descclassname">pymasq.metrics.risk_scores.</code><code class="sig-name descname">is_k_anon</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">key_vars</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">k</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">5</span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#pymasq.metrics.risk_scores.is_k_anon" title="Permalink to this definition"></a></dt>
<dd><p>This function takes in a data frame, a k, and list of key variables and
returns a boolean value for which True if the entire dataframe meets the
condition for k-anonymity and False if it fails to meet the condition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>pd.DataFrame</em>) – A data frame containing records used to calculate k-anonymity</p></li>
<li><p><strong>key_vars</strong> (<em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – A list of the column names from the data frame (df) that will be
included in the k-anonymity calculation
(Default: None, all columns will be included)</p></li>
<li><p><strong>k</strong> (<em>int</em><em>, </em><em>optional</em>) – An integer for k that denotes the threshold for how many unique samples
can be in a group
(Default: 5)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>True if the entire dataframe is k anonymous, False if not</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
<p class="rubric">Examples</p>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.risk_scores.is_k_anon_col">
<code class="sig-prename descclassname">pymasq.metrics.risk_scores.</code><code class="sig-name descname">is_k_anon_col</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">key_vars</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">k</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">5</span></em><span class="sig-paren">)</span> &#x2192; pandas.core.frame.DataFrame<a class="headerlink" href="#pymasq.metrics.risk_scores.is_k_anon_col" title="Permalink to this definition"></a></dt>
<dd><p>This function takes in a data frame, a k, and list of key variables and
returns the data frame with a boolean column added labeled “is_k_anon”
which contains True if the row meets the condition for k-anonymity and False
if it fails to meet the condition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>pd.DataFrame</em>) – A data frame containing records used to calculate k-anonymity</p></li>
<li><p><strong>key_vars</strong> (<em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – A list of the column names from the data frame (df) that will be included in the
k-anonymity calculation
(Default: None, all columns will be included)</p></li>
<li><p><strong>k</strong> (<em>int</em><em>, </em><em>optional</em>) – An integer for k that denotes the threshold for how many unique samples can be in a group
(Default: 5)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Data frame with k-anonymous column added</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pd.dataframe</p>
</dd>
</dl>
<p class="rubric">Examples</p>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.risk_scores.is_l_diverse">
<code class="sig-prename descclassname">pymasq.metrics.risk_scores.</code><code class="sig-name descname">is_l_diverse</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">L</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">2</span></em>, <em class="sig-param"><span class="n">method</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#pymasq.metrics.risk_scores.is_l_diverse" title="Permalink to this definition"></a></dt>
<dd><p>Determines if the data set is not l-diverse for a given l value.</p>
<p>L-diversity is the deterimination that there are l ‘well-represented’ values for sensitive attribute (column) for
an equivalence class or q-block. A dataset is considered l-diverse if every q-block is l-diverse.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>pd.DataFrame</em>) – A data frame with data that l-diversity is being measured for</p></li>
<li><p><strong>sensitive_col</strong> (<em>str</em>) – The name of the column containing the data that is being obscured by mitigations</p></li>
<li><p><strong>L</strong> (<em>int</em><em>, </em><em>optional</em>) – The threshold by which the closeness of the q-blocks and the full dataset are compared. Default is arbitrary.
(Default: 2)</p></li>
<li><p><strong>method</strong> (<em>str {'distinct'</em><em>, </em><em>'entropy'}</em><em>, </em><em>optional</em>) – <p>The method of l-diversity being applied. From Wikipedia:</p>
<blockquote>
<div><ul>
<li><p>Distinct l-diversity – The simplest definition ensures that at least L distinct values for the sensitive</p></li>
</ul>
<p>field in each equivalence class exist.</p>
<ul>
<li><p>Entropy l-diversity – The most complex definition defines Entropy of an equivalent class E to be the</p></li>
</ul>
<p>negation of summation of s across the domain of the sensitive attribute of p(E,s)log(p(E,s)) where p(E,s)
is the fraction of records in E that have the sensitive value s. A table has entropy l-diversity when for
every equivalent class E, Entropy(E) ≥ log(L).</p>
</div></blockquote>
<p>(Default: ‘distinct’)</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> – Boolean indicating if the dataset is l-diverse for a given l value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/L-diversity">https://en.wikipedia.org/wiki/L-diversity</a>
<a class="reference external" href="https://www.cs.purdue.edu/homes/ninghui/papers/t_closeness_icde07.pdf">https://www.cs.purdue.edu/homes/ninghui/papers/t_closeness_icde07.pdf</a></p>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.risk_scores.is_t_close">
<code class="sig-prename descclassname">pymasq.metrics.risk_scores.</code><code class="sig-name descname">is_t_close</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">t</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">datatype</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'categorical'</span></em>, <em class="sig-param"><span class="n">qi</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#pymasq.metrics.risk_scores.is_t_close" title="Permalink to this definition"></a></dt>
<dd><p>Determines if the t-closeness is more than the parameter t
:param df: A data frame with data that t-closeness is being measured for
:type df: pd.DataFrame
:param sensitive_col: The name of only one column containing the data that is being obscured by mitigations
:type sensitive_col: str
:param t: The threshold by which the closeness of the q-blocks and the full dataset are compared. Default is arbitrary.</p>
<blockquote>
<div><p>(Default: 0.1)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>datatype</strong> (<em>str {'categorical'</em><em>, </em><em>'numeric'}</em><em>, </em><em>optional</em>) – The datatype of the senstive column, must be either ‘categorical’ or ‘numeric’
(Default: ‘categorical’)</p></li>
<li><p><strong>qi</strong> (<em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – Columns to be considered as the quasi-indicators. If not provided it is assumed that all columns
but the sensitive column are the quasi-indicators.
(Default: None)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> – Whether the dataset is t-close or not.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.risk_scores.k_anon">
<code class="sig-prename descclassname">pymasq.metrics.risk_scores.</code><code class="sig-name descname">k_anon</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">key_vars</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">k</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">5</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">''</span></em>, <em class="sig-param"><span class="n">label</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">''</span></em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#pymasq.metrics.risk_scores.k_anon" title="Permalink to this definition"></a></dt>
<dd><p>This function calculates the percent of records, or rows, in a data frame that violate
k-anonymity, such that a record that violates k-anonymity contains duplicate values within
the key_vars columns such that when the group is counted it is less than or equal to k as
defined by the user.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>pd.DataFrame</em>) – A data frame containing records used to calculate k-anonymity</p></li>
<li><p><strong>key_vars</strong> (<em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – A list of the column names from the data frame (df) that will be included in the k-anonymity calculation
(Default: None)</p></li>
<li><p><strong>k</strong> (<em>int</em><em>, </em><em>optional</em>) – An integer for k that denotes the threshold for how many unique samples can be in a group
(Default: 5)</p></li>
<li><p><strong>sensitive_col</strong> (<em>str</em><em>, </em><em>optional</em>) – A string of the column name in the data frame that contains the labels for groups, if not included then the
k-anonymity will be calculated for the whole data frame
(Default: “”)</p></li>
<li><p><strong>label</strong> (<em>str</em><em>, </em><em>optional</em>) – A string for the group that the risk will be calculated for
(Default: “”)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Percent of records that violate k-anonymity for the given columns (key_vars) in the data frame (df)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
<p class="rubric">Examples</p>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.risk_scores.l_diversity">
<code class="sig-prename descclassname">pymasq.metrics.risk_scores.</code><code class="sig-name descname">l_diversity</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">L</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">2</span></em>, <em class="sig-param"><span class="n">method</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#pymasq.metrics.risk_scores.l_diversity" title="Permalink to this definition"></a></dt>
<dd><p>Calculates the proportion of the rows with an l-diversity larger than the given <cite>L</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>pd.DataFrame</em>) – A data frame with data that l-diversity is being measured for</p></li>
<li><p><strong>sensitive_col</strong> (<em>str</em><em>,</em>) – The name of the column containing the data that is being obscured by mitigations</p></li>
<li><p><strong>L</strong> (<em>int</em><em>, </em><em>optional</em>) – The threshold by which the closeness of the q-blocks and the full dataset are compared
(Default: 2)</p></li>
<li><p><strong>method</strong> (<em>str {'distinct'</em><em>, </em><em>'entropy'}</em><em>, </em><em>optional</em>) – The method of l-diversity being applied.
(Default: ‘distinct’)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Percent of records that violate l-diversity</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/L-diversity">https://en.wikipedia.org/wiki/L-diversity</a>
<a class="reference external" href="https://www.cs.purdue.edu/homes/ninghui/papers/t_closeness_icde07.pdf">https://www.cs.purdue.edu/homes/ninghui/papers/t_closeness_icde07.pdf</a></p>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.risk_scores.t_closeness">
<code class="sig-prename descclassname">pymasq.metrics.risk_scores.</code><code class="sig-name descname">t_closeness</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">t</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">datatype</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">qi</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">test</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em><span class="sig-paren">)</span> &#x2192; Union<span class="p">[</span>List<span class="p">, </span>float<span class="p">]</span><a class="headerlink" href="#pymasq.metrics.risk_scores.t_closeness" title="Permalink to this definition"></a></dt>
<dd><p>Determines if the t-closeness is more than the parameter t
:param df: A data frame with data that t-closeness is being measured for
:type df: pd.DataFrame
:param sensitive_col: The name of only one column containing the data that is being obscured by mitigations
:type sensitive_col: str
:param t: The threshold by which the closeness of the q-blocks and the full dataset are compared</p>
<blockquote>
<div><p>(Default: 0.1)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>datatype</strong> (<em>str {'categorical'</em><em>, </em><em>'numeric'}</em><em>, </em><em>optional</em>) – The datatype of the sensitive column, must be either ‘categorical’ or ‘numeric’
(Default: ‘categorical’)</p></li>
<li><p><strong>qi</strong> (<em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – Columns to be considered as the quasi-indicators. If not provided it is assumed that all columns
but the sensitive column are the quasi-indicators.
(Default: None)</p></li>
<li><p><strong>test</strong> (<em>bool</em><em>, </em><em>optional</em>) – If true function returns list of closeness measurements (for testing only)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The proportion of the rows that are closer than the t threshold</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-pymasq.metrics.suda">
<span id="pymasq-metrics-suda-module"></span><h2>pymasq.metrics.suda module<a class="headerlink" href="#module-pymasq.metrics.suda" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt id="pymasq.metrics.suda.suda">
<code class="sig-prename descclassname">pymasq.metrics.suda.</code><code class="sig-name descname">suda</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">cols</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Dict<span class="p">[</span>Any<span class="p">, </span>Any<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; pandas.core.frame.DataFrame<a class="headerlink" href="#pymasq.metrics.suda.suda" title="Permalink to this definition"></a></dt>
<dd><p>TODO</p>
</dd></dl>

</section>
<section id="module-pymasq.metrics.utility_scores">
<span id="pymasq-metrics-utility-scores-module"></span><h2>pymasq.metrics.utility_scores module<a class="headerlink" href="#module-pymasq.metrics.utility_scores" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt id="pymasq.metrics.utility_scores.jensen_shannon">
<code class="sig-prename descclassname">pymasq.metrics.utility_scores.</code><code class="sig-name descname">jensen_shannon</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">orig_df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">mod_df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">preprocessor</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'embeddings'</span></em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#pymasq.metrics.utility_scores.jensen_shannon" title="Permalink to this definition"></a></dt>
<dd><p>Computes the Jensen-Shannon distance (not the divergence) of two data frames with same columns
and dimensions. Results are between 1.0 to 0.0, where</p>
<blockquote>
<div><p>1.0 is ‘there is complete difference between the data frames’ and
0.0 is ‘there is no distinction between the two data frames.’</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>orig_df</strong> (<em>pd.DataFrame</em>) – A data frame that contains the original, unaltered data.</p></li>
<li><p><strong>mod_df</strong> (<em>pd.DataFrame</em>) – A data frame with the same shape and column names as orig_df, but with modified values</p></li>
<li><p><strong>sensitive_col</strong> (<em>str</em>) – A string for the column name in the data frame that contains binary labels</p></li>
<li><p><strong>preprocessor</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>Default: &quot;embeddings&quot;</em><em>)</em>) – <dl class="simple">
<dt>A string indicating what pre-processor to use. Options are:</dt><dd><p>”embeddings” (Default) uses pymasq.preprocessing
“label_encode” uses pymasq.preprocessing.label_encode()
None uses none (i.e., the data is already pre-processed)</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A distance between 0.0 and 1.0.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.utility_scores.propensity_score">
<code class="sig-prename descclassname">pymasq.metrics.utility_scores.</code><code class="sig-name descname">propensity_score</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">orig_df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">mod_df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">test_size</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">1234</span></em>, <em class="sig-param"><span class="n">preprocessor</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">'embeddings'</span></em>, <em class="sig-param"><span class="n">method</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'encv'</span></em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#pymasq.metrics.utility_scores.propensity_score" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>Uses elasticnet to train an optimized logisitic regression model to classify the difference between the original and</dt><dd><p>modified data frames and returns the Area Under the ROC Curve (AUC) normalized to between 1.0 to 0.0, where 1.0 is ‘there
is complete difference between the data frames’ and 0.0 is ‘there is no distinction between the two data frames.’</p>
</dd>
</dl>
<p>This function trains a classifier where class 0 is the orig_df and class 1 is the mod_df. The classifier is trained
based on a  fraction of the two dataframes and then tested on the remaining fraction. The AUC score for the prediction
is returned as the score.</p>
<p>How is this different than AUC_Score? AUC Score trains a classifier based on orig_df in order to predict the values in sensitive_col from
the values in the other columns. It then applies the classifier to the mod_df — that is, based on the
values in the other columns in mod_df, it uses the trained classifier to predict the values in the sensitve_column
of mod_df. The AUC score for the prediction is returned as the score.</p>
<p>Propensity stacks the orig_df and mod_df in one combined df. It then adds a
0/1 column that specifies the class of the row original. The combined frame is split into train and test. The classifer
is trained to determine the class of each row. The classifier is then tested. Propensity is the AUC score for the prediction.)</p>
<dl>
<dt>AUC_SCORE:</dt><dd><dl class="simple">
<dt>Train(orig, predict[sensitive]) -&gt;</dt><dd><ul class="simple">
<li><p>Test(orig, predict[sensity])</p></li>
<li><p>Test(mod, predict[sensity])</p></li>
</ul>
</dd>
</dl>
<p>Difference in test performance is AUC_Score</p>
</dd>
<dt>PROPENSITY:</dt><dd><p>combined = orig+mod with new column
traindf = x% of combined
testdf = (1-x)% of combined
Classifer(traindf, predict[new column])</p>
<blockquote>
<div><ul class="simple">
<li><p>Test(testdf, predict[new column])</p></li>
</ul>
</div></blockquote>
<p>Propensity of the area under the curve from Test()ing</p>
</dd>
</dl>
<p>1.0 indicates high disimilarity between orig_df and mod_df
0.0 indicates high similarity between orig_df and mod_df</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>orig_df</strong> (<em>pd.DataFrame</em>) – A data frame that contains the original, unaltered data.</p></li>
<li><p><strong>mod_df</strong> (<em>pd.DataFrame</em>) – A data frame with the same shape and column names as orig_df, but the values. Must have the same columns as orig_df.</p></li>
<li><p><strong>sensitive_col</strong> (<em>str</em>) – A string for the column name in the data frame that contains binary labels</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>Default: -1</em><em>)</em>) – <dl class="simple">
<dt>Number of workers to use for parallel processing</dt><dd><p>-1 indicates use all available workers</p>
</dd>
</dl>
</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>Default: 1234</em><em>)</em>) – Integer seed for setting the random state in the model</p></li>
<li><p><strong>preprocessor</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>Default: &quot;embeddings&quot;</em><em>)</em>) – <dl class="simple">
<dt>A string indicating what pre-processor to use. Options are:</dt><dd><p>”embeddings” (Default) uses pymasq.preprocessing.preprocess_data()
“label_encode” uses pymasq.preprocessing.label_encode()
None uses none (i.e., the data is already pre-processed)</p>
</dd>
</dl>
</p></li>
<li><p><strong>method</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>Default: &quot;encv&quot;</em><em>)</em>) – <dl class="simple">
<dt>A string indicating what classier to use. Options are:</dt><dd><p>”envc” (Default) uses sklearn’s ElasticNetVC()
“larscv” uses sklearn’s LarsCV()</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The normalized reverse AUC score between 0.0 and 1.0</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.utility_scores.proportion_diff_score">
<code class="sig-prename descclassname">pymasq.metrics.utility_scores.</code><code class="sig-name descname">proportion_diff_score</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">orig_df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">mod_df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymasq.metrics.utility_scores.proportion_diff_score" title="Permalink to this definition"></a></dt>
<dd><p>Calculates the proportion of cells that are different (i.e., not equal) between two data
frames and returns a proportion between 1.0 to 0.0.</p>
<p>1.0 indicates high disimilarity between orig_df and mod_df
0.0 indicates high similarity between orig_df and mod_df</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>orig_df</strong> (<em>pd.DataFrame</em>) – A data frame that contains the original, unaltered data.</p></li>
<li><p><strong>mod_df</strong> (<em>pd.DataFrame</em>) – A data frame with the same shape and column names as orig_df, but the values</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The proportion difference score between 0.0 and 1.0.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-pymasq.metrics.utils">
<span id="pymasq-metrics-utils-module"></span><h2>pymasq.metrics.utils module<a class="headerlink" href="#module-pymasq.metrics.utils" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt id="pymasq.metrics.utils.uniq_col_name">
<code class="sig-prename descclassname">pymasq.metrics.utils.</code><code class="sig-name descname">uniq_col_name</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span></em>, <em class="sig-param"><span class="n">prefix</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'class'</span></em><span class="sig-paren">)</span> &#x2192; str<a class="headerlink" href="#pymasq.metrics.utils.uniq_col_name" title="Permalink to this definition"></a></dt>
<dd><p>Helper function to return a column name that is unique given
existing column names in the dataframe.</p>
<p>Uniqueness is provided via a 32-bit random int as a suffix</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>pd.dataFrame</em>) – A dataframe with a set of columns</p></li>
<li><p><strong>prefix</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>Default: &quot;class&quot;</em><em>)</em>) – the prefix of the new column name.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The new column name as a string. The df is not modified</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-pymasq.metrics">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-pymasq.metrics" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt id="pymasq.metrics.auc_score">
<code class="sig-prename descclassname">pymasq.metrics.</code><code class="sig-name descname">auc_score</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">orig_df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">mod_df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">method</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">preprocessor</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'embeddings'</span></em>, <em class="sig-param"><span class="n">modeling_task</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">cache_location</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">absolute_risk</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">retrain</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#pymasq.metrics.auc_score" title="Permalink to this definition"></a></dt>
<dd><p>Calculates the AUC score for the provided original and modified dataframes given the target
column name and cache folder.</p>
<p>AUC Score trains a classifier based on orig_df in order to predict the values in sensitive_col from
the values in the other columns. It then applies the classifier to the mod_df — that is, based on the
values in the other columns in mod_df, it uses the trained classifier to predict the values in the sensitve_column
of mod_df. The AUC score for the prediction is returned as the score.</p>
<p>How is this different than propensity? Propensity stacks the orig_df and mod_df in one combined df. It then adds a
0/1 column that specifies the class of the row original. The combined frame is split into train and test. The classifer
is trained to determine the class of each row. The classifier is then tested. Propensity is the AUC score for the prediction.)</p>
<dl>
<dt>AUC_SCORE:</dt><dd><dl class="simple">
<dt>Train(orig, predict[sensitive]) -&gt;</dt><dd><ul class="simple">
<li><p>Test(orig, predict[sensity])</p></li>
<li><p>Test(mod, predict[sensity])</p></li>
</ul>
</dd>
</dl>
<p>Difference in test performance is AUC_Score</p>
</dd>
<dt>PROPENSITY:</dt><dd><p>combined = orig+mod with new column
traindf = x% of combined
testdf = (1-x)% of combined
Classifer(traindf, predict[new column])</p>
<blockquote>
<div><ul class="simple">
<li><p>Test(testdf, predict[new column])</p></li>
</ul>
</div></blockquote>
<p>Propensity of the area under the curve from Test()ing</p>
</dd>
</dl>
<p>1.0 indicates high disimilarity between orig_df and mod_df
0.0 indicates high similarity between orig_df and mod_df</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>orig_df</strong> (<em>pd.Dataframe</em>) – Data frame containing the original unaltered data</p></li>
<li><p><strong>mod_df</strong> (<em>pd.Dataframe</em>) – Data frame containing the modified data after application of mitigation(s)</p></li>
<li><p><strong>sensitive_col</strong> (<em>str</em>) – String of sensitive column name in the data frame that contains labels</p></li>
<li><p><strong>method</strong> (<em>str</em>) – <p>The classifier method to use. There are several options.
- “encv” denotes the sklearn ElasticNetCV regressor
- “larscv” denotes the sklearn LarsCV regressor
- “rfreg” denotes the sklearn Random Forest regressor
- “logreg” denotes the sklearn Logisitc RegressionCV classifier
- “rfclass” denotes the sklearn Random Forest classifier
- “tpotreg” denotes the use of a pre-trained TPOT regressor. To pre-train</p>
<blockquote>
<div><p>TPOT call pymasq.models.TpotRegressor.train(), which will save the trained
model to a cache location. If a different than the default pymasq location is
used, specify the path in the “cache_location” argument. If method is “tpot”,
then “tpot_fname” should be passed as a named keyword argument.</p>
</div></blockquote>
<ul>
<li><p>”tpotclass” denotes the use of a pre-trained TPOT classifer. To pre-train
TPOT call pymasq.models.TpotClassifier.train(), which will save the trained
model to a cache location. If a different than the default pymasq location is
used, specify the path in the “cache_location” argument. If method is “tpot”,
then “tpot_fname” should be passed as a named keyword argument.</p></li>
</ul>
</p></li>
<li><p><strong>preprocessor</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>Default: 'embeddings'</em><em>)</em>) – The pymasq preprocessor to use. There are several options.
- ‘embeddings’: advanced processing of numeric and categorical data.
- ‘label_encode’: skLearn-based encoding of categorical data only
- None: the dataframes are not processed and assumed ready for use by a classifier</p></li>
<li><p><strong>modeling_task</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>Default: None</em><em>)</em>) – Type of modeling used to prepare model and preprocessor, if not set then it
will calculated from the sensitive column</p></li>
<li><p><strong>cache_location</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>Default: None</em><em>)</em>) – String for the directory path to the cache for the current TPOT data</p></li>
<li><p><strong>absolute_risk</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>Default: False</em><em>)</em>) – Boolean flag that, when true, calculates the absolute risk score.</p></li>
<li><p><strong>retrain</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>Default: True</em><em>)</em>) – Whether to ignore cached training data</p></li>
<li><p><strong>**kwargs</strong> (<em>Dict</em><em>[</em><em>Any</em><em>, </em><em>Any</em><em>]</em>) – Values for algorithm-specific headers to be added to called method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The auc score, as absolute risk or as a risk score</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.beta_likeness">
<code class="sig-prename descclassname">pymasq.metrics.</code><code class="sig-name descname">beta_likeness</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">beta</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>int<span class="p">, </span>float<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">qi</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">enhanced</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">bool_return</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em><span class="sig-paren">)</span> &#x2192; Union<span class="p">[</span>bool<span class="p">, </span>float<span class="p">]</span><a class="headerlink" href="#pymasq.metrics.beta_likeness" title="Permalink to this definition"></a></dt>
<dd><p>Determines the percent of entries in the data that do not satisfy beta-likeness. If
bool_return is set to True, returns True if the entire dataset satisfies beta-likeness for a
given beta value, False otherwise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>pd.DataFrame</em>) – A data frame with data that beta-likeness is being measured for</p></li>
<li><p><strong>sensitive_col</strong> (<em>str</em>) – The name of only one column containing the data that is being obscured by mitigations</p></li>
<li><p><strong>beta</strong> (<em>float</em><em> (</em><em>&gt;0</em><em>)</em><em>, </em><em>optional</em>) – The tolerance threshold for the increase in confidence of a certain sensitive attribute,
in relative difference terms, for SAs in an equivalence class versus the total population
(Default: 1.0)</p></li>
<li><p><strong>qi</strong> (<em>List</em><em>, </em><em>optional</em>) – Columns to be considered as the quasi-indicators. If not provided it is assumed that all columns
but the sensitive column are the quasi-indicators.
(Default: None)</p></li>
<li><p><strong>enhanced</strong> (<em>bool</em><em>, </em><em>optional</em>) – Should the function run enhanced beta-likeness instead of basic beta-likeness.
(Default: True)</p></li>
<li><p><strong>bool_return</strong> (<em>bool</em><em>, </em><em>optional</em>) – Should the function return a boolean indicating True if beta-likeness is satisfied/False
if beta-likeness is not satisfied.
(Default: False)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>bool</em> – If the <cite>bool_return</cite> flag is set to True, the function will return True if the supplied dataframe
satisfies beta likeness for the supplied sensitive column and beta value</p></li>
<li><p><em>float</em> – The proportion of the rows that fail beta-likeness</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference internal" href="pymasq.errors.html#pymasq.errors.InputError" title="pymasq.errors.InputError"><strong>InputError</strong></a> – This error is raised when a <cite>beta</cite> value of &lt;= 0 is supplied.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.indiv_risk">
<code class="sig-prename descclassname">pymasq.metrics.</code><code class="sig-name descname">indiv_risk</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>int<span class="p">, </span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">quasi_cols</span><span class="p">:</span> <span class="n">List<span class="p">[</span>Union<span class="p">[</span>int<span class="p">, </span>str<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">method</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'approx'</span></em>, <em class="sig-param"><span class="n">weights</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>Union<span class="p">[</span>int<span class="p">, </span>float<span class="p">]</span><span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">qual</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>int<span class="p">, </span>float<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymasq.metrics.indiv_risk" title="Permalink to this definition"></a></dt>
<dd><p>Calculate the individual risk each value contributes in re-identifying sensitve variable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>DataFrame</em><em>, </em><em>Series</em><em>, or </em><em>array_like</em>) – The data to be modified.</p></li>
<li><p><strong>sensitive_col</strong> (<em>str</em><em> or </em><em>int</em>) – Column whos relationship to other columns needs to be obfuscated.</p></li>
<li><p><strong>quasi_cols</strong> (<em>list</em>) – Columns to consider when calculating individual risk of re-identifying <cite>sensitive_col</cite>.</p></li>
<li><p><strong>method</strong> (<em>{'approx'</em><em>, </em><em>'exact'}</em><em> (</em><em>Default: 'approx'</em><em>)</em>) – Precision for calculating the individual risk of each value.</p></li>
<li><p><strong>weights</strong> (<em>list</em><em>, </em><em>optional</em><em> (</em><em>Default: None</em><em>)</em>) – Proportion of rows with the same combination of values in <cite>data</cite> for
each row in <cite>data</cite>, only to be used if <cite>data</cite> is a sample/subset of a larger dataset.
If None, <cite>weights</cite> will be a unit vector indicating that <cite>data</cite> is the full population.</p></li>
<li><p><strong>qual</strong> (<em>float</em><em> (</em><em>0</em><em>, </em><em>1</em><em>]</em><em>, </em><em>optional</em><em> (</em><em>Default: 1</em><em>)</em>) – Perceived quality of frequency counts to act as a final correction factor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A DataFrame with the individual risk values of each row.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>DataFrame</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>InputError:</strong> – Raised when invalid arguments are passed.</p></li>
<li><p><a class="reference internal" href="pymasq.errors.html#pymasq.errors.NotInRangeError" title="pymasq.errors.NotInRangeError"><strong>NotInRangeError</strong></a> – Raised if <cite>risk_threshold</cite> is outside the interval [0, 1].</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.indiv_risk_approx">
<code class="sig-prename descclassname">pymasq.metrics.</code><code class="sig-name descname">indiv_risk_approx</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">fk</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>int<span class="p">, </span>float<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">Fk</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>int<span class="p">, </span>float<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#pymasq.metrics.indiv_risk_approx" title="Permalink to this definition"></a></dt>
<dd><p>calculates the approximate individual risk</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fk</strong> (<em>int</em><em> or </em><em>float</em>) – the sample frequency of the row’s combination of quasi-identifier values</p></li>
<li><p><strong>Fk</strong> (<em>int</em><em> or </em><em>float</em>) – the population frequence of the row’s combination of quasi-identifier values</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>risk score in [0, 1]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>TODO</p>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.indiv_risk_exact">
<code class="sig-prename descclassname">pymasq.metrics.</code><code class="sig-name descname">indiv_risk_exact</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">fk</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">Fk</span><span class="p">:</span> <span class="n">float</span></em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#pymasq.metrics.indiv_risk_exact" title="Permalink to this definition"></a></dt>
<dd><p>calculates the exact individual risk</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fk</strong> (<em>int</em>) – the sample frequency of the row’s combination of quasi-identifier values</p></li>
<li><p><strong>Fk</strong> (<em>int</em>) – the population frequence of the row’s combination of quasi-identifier values</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>risk score in [0, 1]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>TODO</p>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.is_beta_like">
<code class="sig-prename descclassname">pymasq.metrics.</code><code class="sig-name descname">is_beta_like</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">beta</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">qi</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">enhanced</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#pymasq.metrics.is_beta_like" title="Permalink to this definition"></a></dt>
<dd><p>Determines if the beta-likeness is satisfied for parameter beta</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>pd.DataFrame</em>) – A data frame with data that beta-likeness is being measured for</p></li>
<li><p><strong>sensitive_col</strong> (<em>str</em>) – The name of only one column containing the data that is being obscured by mitigations</p></li>
<li><p><strong>beta</strong> (<em>float</em><em> (</em><em>&gt;0</em><em>)</em><em>, </em><em>optional</em>) – The tolerance threshold for the increase in confidence of a certain sensitive attribute,
in relative difference terms, for SAs in an equivalence class versus the total population
(Default: 1.0)</p></li>
<li><p><strong>qi</strong> (<em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – Columns to be considered as the quasi-indicators. If not provided it is assumed that all columns
but the sensitive column are the quasi-indicators.
(Default: None)</p></li>
<li><p><strong>enhanced</strong> (<em>bool</em><em>, </em><em>optional</em>) – Should the function run enhanced beta-likeness instead of basic beta-likeness.
(Default: True)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> – Whether the dataset satisfies beta-likeness or not.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.is_k_anon">
<code class="sig-prename descclassname">pymasq.metrics.</code><code class="sig-name descname">is_k_anon</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">key_vars</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">k</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">5</span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#pymasq.metrics.is_k_anon" title="Permalink to this definition"></a></dt>
<dd><p>This function takes in a data frame, a k, and list of key variables and
returns a boolean value for which True if the entire dataframe meets the
condition for k-anonymity and False if it fails to meet the condition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>pd.DataFrame</em>) – A data frame containing records used to calculate k-anonymity</p></li>
<li><p><strong>key_vars</strong> (<em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – A list of the column names from the data frame (df) that will be
included in the k-anonymity calculation
(Default: None, all columns will be included)</p></li>
<li><p><strong>k</strong> (<em>int</em><em>, </em><em>optional</em>) – An integer for k that denotes the threshold for how many unique samples
can be in a group
(Default: 5)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>True if the entire dataframe is k anonymous, False if not</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
<p class="rubric">Examples</p>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.is_k_anon_col">
<code class="sig-prename descclassname">pymasq.metrics.</code><code class="sig-name descname">is_k_anon_col</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">key_vars</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">k</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">5</span></em><span class="sig-paren">)</span> &#x2192; pandas.core.frame.DataFrame<a class="headerlink" href="#pymasq.metrics.is_k_anon_col" title="Permalink to this definition"></a></dt>
<dd><p>This function takes in a data frame, a k, and list of key variables and
returns the data frame with a boolean column added labeled “is_k_anon”
which contains True if the row meets the condition for k-anonymity and False
if it fails to meet the condition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>pd.DataFrame</em>) – A data frame containing records used to calculate k-anonymity</p></li>
<li><p><strong>key_vars</strong> (<em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – A list of the column names from the data frame (df) that will be included in the
k-anonymity calculation
(Default: None, all columns will be included)</p></li>
<li><p><strong>k</strong> (<em>int</em><em>, </em><em>optional</em>) – An integer for k that denotes the threshold for how many unique samples can be in a group
(Default: 5)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Data frame with k-anonymous column added</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pd.dataframe</p>
</dd>
</dl>
<p class="rubric">Examples</p>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.is_l_diverse">
<code class="sig-prename descclassname">pymasq.metrics.</code><code class="sig-name descname">is_l_diverse</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">L</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">2</span></em>, <em class="sig-param"><span class="n">method</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#pymasq.metrics.is_l_diverse" title="Permalink to this definition"></a></dt>
<dd><p>Determines if the data set is not l-diverse for a given l value.</p>
<p>L-diversity is the deterimination that there are l ‘well-represented’ values for sensitive attribute (column) for
an equivalence class or q-block. A dataset is considered l-diverse if every q-block is l-diverse.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>pd.DataFrame</em>) – A data frame with data that l-diversity is being measured for</p></li>
<li><p><strong>sensitive_col</strong> (<em>str</em>) – The name of the column containing the data that is being obscured by mitigations</p></li>
<li><p><strong>L</strong> (<em>int</em><em>, </em><em>optional</em>) – The threshold by which the closeness of the q-blocks and the full dataset are compared. Default is arbitrary.
(Default: 2)</p></li>
<li><p><strong>method</strong> (<em>str {'distinct'</em><em>, </em><em>'entropy'}</em><em>, </em><em>optional</em>) – <p>The method of l-diversity being applied. From Wikipedia:</p>
<blockquote>
<div><ul>
<li><p>Distinct l-diversity – The simplest definition ensures that at least L distinct values for the sensitive</p></li>
</ul>
<p>field in each equivalence class exist.</p>
<ul>
<li><p>Entropy l-diversity – The most complex definition defines Entropy of an equivalent class E to be the</p></li>
</ul>
<p>negation of summation of s across the domain of the sensitive attribute of p(E,s)log(p(E,s)) where p(E,s)
is the fraction of records in E that have the sensitive value s. A table has entropy l-diversity when for
every equivalent class E, Entropy(E) ≥ log(L).</p>
</div></blockquote>
<p>(Default: ‘distinct’)</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> – Boolean indicating if the dataset is l-diverse for a given l value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/L-diversity">https://en.wikipedia.org/wiki/L-diversity</a>
<a class="reference external" href="https://www.cs.purdue.edu/homes/ninghui/papers/t_closeness_icde07.pdf">https://www.cs.purdue.edu/homes/ninghui/papers/t_closeness_icde07.pdf</a></p>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.is_t_close">
<code class="sig-prename descclassname">pymasq.metrics.</code><code class="sig-name descname">is_t_close</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">t</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">datatype</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'categorical'</span></em>, <em class="sig-param"><span class="n">qi</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#pymasq.metrics.is_t_close" title="Permalink to this definition"></a></dt>
<dd><p>Determines if the t-closeness is more than the parameter t
:param df: A data frame with data that t-closeness is being measured for
:type df: pd.DataFrame
:param sensitive_col: The name of only one column containing the data that is being obscured by mitigations
:type sensitive_col: str
:param t: The threshold by which the closeness of the q-blocks and the full dataset are compared. Default is arbitrary.</p>
<blockquote>
<div><p>(Default: 0.1)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>datatype</strong> (<em>str {'categorical'</em><em>, </em><em>'numeric'}</em><em>, </em><em>optional</em>) – The datatype of the senstive column, must be either ‘categorical’ or ‘numeric’
(Default: ‘categorical’)</p></li>
<li><p><strong>qi</strong> (<em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – Columns to be considered as the quasi-indicators. If not provided it is assumed that all columns
but the sensitive column are the quasi-indicators.
(Default: None)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ret</strong> – Whether the dataset is t-close or not.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.jensen_shannon">
<code class="sig-prename descclassname">pymasq.metrics.</code><code class="sig-name descname">jensen_shannon</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">orig_df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">mod_df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">preprocessor</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'embeddings'</span></em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#pymasq.metrics.jensen_shannon" title="Permalink to this definition"></a></dt>
<dd><p>Computes the Jensen-Shannon distance (not the divergence) of two data frames with same columns
and dimensions. Results are between 1.0 to 0.0, where</p>
<blockquote>
<div><p>1.0 is ‘there is complete difference between the data frames’ and
0.0 is ‘there is no distinction between the two data frames.’</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>orig_df</strong> (<em>pd.DataFrame</em>) – A data frame that contains the original, unaltered data.</p></li>
<li><p><strong>mod_df</strong> (<em>pd.DataFrame</em>) – A data frame with the same shape and column names as orig_df, but with modified values</p></li>
<li><p><strong>sensitive_col</strong> (<em>str</em>) – A string for the column name in the data frame that contains binary labels</p></li>
<li><p><strong>preprocessor</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>Default: &quot;embeddings&quot;</em><em>)</em>) – <dl class="simple">
<dt>A string indicating what pre-processor to use. Options are:</dt><dd><p>”embeddings” (Default) uses pymasq.preprocessing
“label_encode” uses pymasq.preprocessing.label_encode()
None uses none (i.e., the data is already pre-processed)</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A distance between 0.0 and 1.0.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.k_anon">
<code class="sig-prename descclassname">pymasq.metrics.</code><code class="sig-name descname">k_anon</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">key_vars</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">k</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">5</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">''</span></em>, <em class="sig-param"><span class="n">label</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">''</span></em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#pymasq.metrics.k_anon" title="Permalink to this definition"></a></dt>
<dd><p>This function calculates the percent of records, or rows, in a data frame that violate
k-anonymity, such that a record that violates k-anonymity contains duplicate values within
the key_vars columns such that when the group is counted it is less than or equal to k as
defined by the user.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>pd.DataFrame</em>) – A data frame containing records used to calculate k-anonymity</p></li>
<li><p><strong>key_vars</strong> (<em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – A list of the column names from the data frame (df) that will be included in the k-anonymity calculation
(Default: None)</p></li>
<li><p><strong>k</strong> (<em>int</em><em>, </em><em>optional</em>) – An integer for k that denotes the threshold for how many unique samples can be in a group
(Default: 5)</p></li>
<li><p><strong>sensitive_col</strong> (<em>str</em><em>, </em><em>optional</em>) – A string of the column name in the data frame that contains the labels for groups, if not included then the
k-anonymity will be calculated for the whole data frame
(Default: “”)</p></li>
<li><p><strong>label</strong> (<em>str</em><em>, </em><em>optional</em>) – A string for the group that the risk will be calculated for
(Default: “”)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Percent of records that violate k-anonymity for the given columns (key_vars) in the data frame (df)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
<p class="rubric">Examples</p>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.l_diversity">
<code class="sig-prename descclassname">pymasq.metrics.</code><code class="sig-name descname">l_diversity</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">L</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">2</span></em>, <em class="sig-param"><span class="n">method</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#pymasq.metrics.l_diversity" title="Permalink to this definition"></a></dt>
<dd><p>Calculates the proportion of the rows with an l-diversity larger than the given <cite>L</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>pd.DataFrame</em>) – A data frame with data that l-diversity is being measured for</p></li>
<li><p><strong>sensitive_col</strong> (<em>str</em><em>,</em>) – The name of the column containing the data that is being obscured by mitigations</p></li>
<li><p><strong>L</strong> (<em>int</em><em>, </em><em>optional</em>) – The threshold by which the closeness of the q-blocks and the full dataset are compared
(Default: 2)</p></li>
<li><p><strong>method</strong> (<em>str {'distinct'</em><em>, </em><em>'entropy'}</em><em>, </em><em>optional</em>) – The method of l-diversity being applied.
(Default: ‘distinct’)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Percent of records that violate l-diversity</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/L-diversity">https://en.wikipedia.org/wiki/L-diversity</a>
<a class="reference external" href="https://www.cs.purdue.edu/homes/ninghui/papers/t_closeness_icde07.pdf">https://www.cs.purdue.edu/homes/ninghui/papers/t_closeness_icde07.pdf</a></p>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.propensity_score">
<code class="sig-prename descclassname">pymasq.metrics.</code><code class="sig-name descname">propensity_score</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">orig_df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">mod_df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">test_size</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">1234</span></em>, <em class="sig-param"><span class="n">preprocessor</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">'embeddings'</span></em>, <em class="sig-param"><span class="n">method</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'encv'</span></em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#pymasq.metrics.propensity_score" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>Uses elasticnet to train an optimized logisitic regression model to classify the difference between the original and</dt><dd><p>modified data frames and returns the Area Under the ROC Curve (AUC) normalized to between 1.0 to 0.0, where 1.0 is ‘there
is complete difference between the data frames’ and 0.0 is ‘there is no distinction between the two data frames.’</p>
</dd>
</dl>
<p>This function trains a classifier where class 0 is the orig_df and class 1 is the mod_df. The classifier is trained
based on a  fraction of the two dataframes and then tested on the remaining fraction. The AUC score for the prediction
is returned as the score.</p>
<p>How is this different than AUC_Score? AUC Score trains a classifier based on orig_df in order to predict the values in sensitive_col from
the values in the other columns. It then applies the classifier to the mod_df — that is, based on the
values in the other columns in mod_df, it uses the trained classifier to predict the values in the sensitve_column
of mod_df. The AUC score for the prediction is returned as the score.</p>
<p>Propensity stacks the orig_df and mod_df in one combined df. It then adds a
0/1 column that specifies the class of the row original. The combined frame is split into train and test. The classifer
is trained to determine the class of each row. The classifier is then tested. Propensity is the AUC score for the prediction.)</p>
<dl>
<dt>AUC_SCORE:</dt><dd><dl class="simple">
<dt>Train(orig, predict[sensitive]) -&gt;</dt><dd><ul class="simple">
<li><p>Test(orig, predict[sensity])</p></li>
<li><p>Test(mod, predict[sensity])</p></li>
</ul>
</dd>
</dl>
<p>Difference in test performance is AUC_Score</p>
</dd>
<dt>PROPENSITY:</dt><dd><p>combined = orig+mod with new column
traindf = x% of combined
testdf = (1-x)% of combined
Classifer(traindf, predict[new column])</p>
<blockquote>
<div><ul class="simple">
<li><p>Test(testdf, predict[new column])</p></li>
</ul>
</div></blockquote>
<p>Propensity of the area under the curve from Test()ing</p>
</dd>
</dl>
<p>1.0 indicates high disimilarity between orig_df and mod_df
0.0 indicates high similarity between orig_df and mod_df</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>orig_df</strong> (<em>pd.DataFrame</em>) – A data frame that contains the original, unaltered data.</p></li>
<li><p><strong>mod_df</strong> (<em>pd.DataFrame</em>) – A data frame with the same shape and column names as orig_df, but the values. Must have the same columns as orig_df.</p></li>
<li><p><strong>sensitive_col</strong> (<em>str</em>) – A string for the column name in the data frame that contains binary labels</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>Default: -1</em><em>)</em>) – <dl class="simple">
<dt>Number of workers to use for parallel processing</dt><dd><p>-1 indicates use all available workers</p>
</dd>
</dl>
</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>Default: 1234</em><em>)</em>) – Integer seed for setting the random state in the model</p></li>
<li><p><strong>preprocessor</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>Default: &quot;embeddings&quot;</em><em>)</em>) – <dl class="simple">
<dt>A string indicating what pre-processor to use. Options are:</dt><dd><p>”embeddings” (Default) uses pymasq.preprocessing.preprocess_data()
“label_encode” uses pymasq.preprocessing.label_encode()
None uses none (i.e., the data is already pre-processed)</p>
</dd>
</dl>
</p></li>
<li><p><strong>method</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>Default: &quot;encv&quot;</em><em>)</em>) – <dl class="simple">
<dt>A string indicating what classier to use. Options are:</dt><dd><p>”envc” (Default) uses sklearn’s ElasticNetVC()
“larscv” uses sklearn’s LarsCV()</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The normalized reverse AUC score between 0.0 and 1.0</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.proportion_diff_score">
<code class="sig-prename descclassname">pymasq.metrics.</code><code class="sig-name descname">proportion_diff_score</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">orig_df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">mod_df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymasq.metrics.proportion_diff_score" title="Permalink to this definition"></a></dt>
<dd><p>Calculates the proportion of cells that are different (i.e., not equal) between two data
frames and returns a proportion between 1.0 to 0.0.</p>
<p>1.0 indicates high disimilarity between orig_df and mod_df
0.0 indicates high similarity between orig_df and mod_df</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>orig_df</strong> (<em>pd.DataFrame</em>) – A data frame that contains the original, unaltered data.</p></li>
<li><p><strong>mod_df</strong> (<em>pd.DataFrame</em>) – A data frame with the same shape and column names as orig_df, but the values</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The proportion difference score between 0.0 and 1.0.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.suda">
<code class="sig-prename descclassname">pymasq.metrics.</code><code class="sig-name descname">suda</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">cols</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Dict<span class="p">[</span>Any<span class="p">, </span>Any<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; pandas.core.frame.DataFrame<a class="headerlink" href="#pymasq.metrics.suda" title="Permalink to this definition"></a></dt>
<dd><p>TODO</p>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.t_closeness">
<code class="sig-prename descclassname">pymasq.metrics.</code><code class="sig-name descname">t_closeness</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sensitive_col</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">t</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">datatype</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">qi</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">test</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em><span class="sig-paren">)</span> &#x2192; Union<span class="p">[</span>List<span class="p">, </span>float<span class="p">]</span><a class="headerlink" href="#pymasq.metrics.t_closeness" title="Permalink to this definition"></a></dt>
<dd><p>Determines if the t-closeness is more than the parameter t
:param df: A data frame with data that t-closeness is being measured for
:type df: pd.DataFrame
:param sensitive_col: The name of only one column containing the data that is being obscured by mitigations
:type sensitive_col: str
:param t: The threshold by which the closeness of the q-blocks and the full dataset are compared</p>
<blockquote>
<div><p>(Default: 0.1)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>datatype</strong> (<em>str {'categorical'</em><em>, </em><em>'numeric'}</em><em>, </em><em>optional</em>) – The datatype of the sensitive column, must be either ‘categorical’ or ‘numeric’
(Default: ‘categorical’)</p></li>
<li><p><strong>qi</strong> (<em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – Columns to be considered as the quasi-indicators. If not provided it is assumed that all columns
but the sensitive column are the quasi-indicators.
(Default: None)</p></li>
<li><p><strong>test</strong> (<em>bool</em><em>, </em><em>optional</em>) – If true function returns list of closeness measurements (for testing only)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The proportion of the rows that are closer than the t threshold</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pymasq.metrics.uniq_col_name">
<code class="sig-prename descclassname">pymasq.metrics.</code><code class="sig-name descname">uniq_col_name</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span></em>, <em class="sig-param"><span class="n">prefix</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'class'</span></em><span class="sig-paren">)</span> &#x2192; str<a class="headerlink" href="#pymasq.metrics.uniq_col_name" title="Permalink to this definition"></a></dt>
<dd><p>Helper function to return a column name that is unique given
existing column names in the dataframe.</p>
<p>Uniqueness is provided via a 32-bit random int as a suffix</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>pd.dataFrame</em>) – A dataframe with a set of columns</p></li>
<li><p><strong>prefix</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>Default: &quot;class&quot;</em><em>)</em>) – the prefix of the new column name.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The new column name as a string. The df is not modified</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MITLL.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>